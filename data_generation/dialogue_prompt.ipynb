{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3940bc0f-40ab-476e-a598-d9ab33d5c2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import openai\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6126b7b2-d666-48cd-9133-29c03c28b1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_jsonl(filename):\n",
    "    records = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            records.append(json.loads(line))\n",
    "    return records\n",
    "\n",
    "def save_json(data, filename):\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, indent=4)\n",
    "\n",
    "def save_jsonl(data_list, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for record in data_list:\n",
    "            json.dump(record, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "def pickle_save(obj, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c383b-4e87-4edb-af60-54decadcebc2",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeff41b-e0ca-4c2a-bb8b-e034c9a55baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = load_jsonl(\"DECODE[dialogue-contradiction-detection]/decode_v0.1/test.jsonl\")\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e749ce-52a1-443b-ab49-1abddbe6456e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_with_contradiction = []\n",
    "samples_no_contradiction = []\n",
    "for i, x in enumerate(test_set):\n",
    "    if x[\"is_contradiction\"]:\n",
    "        samples_with_contradiction.append((i, x))\n",
    "    else:\n",
    "        samples_no_contradiction.append((i, x))\n",
    "print(len(samples_with_contradiction), len(samples_no_contradiction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015d1b62-0f92-47c2-9ec5-ded52bcd0c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_contra_random_samples = random.sample(samples_with_contradiction, 100)\n",
    "no_contra_random_samples = random.sample(samples_no_contradiction, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b8cc58-2be0-42d3-8b1b-b75c8f597ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_instance(sample):\n",
    "    index, instance = sample\n",
    "    contradiction_indices = instance['aggregated_contradiction_indices']\n",
    "    contradiction_indices = [x for x in contradiction_indices if x != len(instance['turns']) - 1]  # remove the last utterance, because it is always there\n",
    "    # print(\"contra ids\", contradiction_indices)\n",
    "    for t in sorted(instance['turns'], key=lambda x: x['turn_id']):\n",
    "        if t['turn_id'] in contradiction_indices:\n",
    "            print(Back.YELLOW + f\"{t['agent_id']}: {t['text']}\", end=\"\")\n",
    "            print(Style.RESET_ALL)\n",
    "        elif t['auxiliary']['contradiction']:\n",
    "            print(Fore.RED + f\"{t['agent_id']}: {t['text']}\", end=\"\")\n",
    "            print(Style.RESET_ALL)\n",
    "        else:\n",
    "            print(f\"{t['agent_id']}: {t['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b79bc-b11d-4027-bb66-bd833141df65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# an example with contradiction\n",
    "# the last utterance (red) is contradicting to the 4-th utterance (highlighed in yellow)\n",
    "show_instance(with_contra_random_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b70fe-1daf-4a5e-b7ee-96f9611e5184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# an example without contradiction\n",
    "show_instance(no_contra_random_samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4a28d-6184-4397-8627-c165772e56a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Construct Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e7d74-625c-43eb-9516-5fbe89b90fa6",
   "metadata": {},
   "source": [
    "Note: no need to distinguish between samples with/without contradiction when constructing prompt (I previously did this to test label-reversing modifications. But not required at the moment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f49729-b1b0-43bd-a331-e175bc5af3de",
   "metadata": {},
   "source": [
    "Differences compared to sent's version\n",
    "* mention that modification should be done on LAST TURN\n",
    "* two fields: DIALOGUE and LAST TURN\n",
    "* mention that the modified LAST TURN is still coherent with the previous dialogue context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff12324-4fa5-4ee6-ac82-5f105d58e28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_instruction = '''You are a linguist specializing in doing text annotation in the English language. You will be tasked with making minimal modification to the LAST TURN of a conversation based on some linguistics aspects to expose biases in machine learning models. Maker sure the modified LAST TURN is still coherent with previous dialogue context.\n",
    "\n",
    "The given text are samples in the conversational contradiction detection task.\n",
    "\n",
    "Each sample has two fields: \n",
    "- DIALOGUE: a conversation with multiple turns.\n",
    "- LAST TURN: the last turn/utterance of the conversation\n",
    "\n",
    "A task may ask for one or multiple modifications for LAST TURN. Each modification should be an object with 3 fields: \n",
    "type: the type of modification\n",
    "modified_last_turn: the modified last turn of the dialogue.\n",
    "rationale: the reason why and how the modifications are made.\n",
    "\n",
    "Please return a json object which consists of one or multiple modifications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da76d67-76ed-4ffe-9423-a6cf6906951f",
   "metadata": {},
   "source": [
    "## example: antiderivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa84aa-0f04-4e14-b6ec-ce277474122f",
   "metadata": {},
   "source": [
    "Differences compared to sent's version\n",
    "* the prompt specifies that modification should be done for the LAST TURN\n",
    "* only gives task instruction and examples (so we can append the DIALOGUE and the LAST TURN later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ac81a-1689-4e2b-bc32-c23b83633f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "antiderivation_replacement_instruction ='''Find any non-derived word (a word without suffixes or prefixes) in the LAST TURN below and change it into a derived word (word with a prefix or a suffix). Do not add grammatical suffixes (-s, -ed, -er, -est). Make sure the conversation is natural after modification.\n",
    "\n",
    "Example: a sometimes dull film ->  a sometimes tedious film (tedious is derived from tedium using a -ios suffix)\n",
    "\n",
    "Example: an very hard task -> an increasingly hard task (increasingly is derived from increasing using a -ly suffix)\n",
    "\n",
    "Example: amazing accomplishment -> Skip (both words are already derived)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9e22ad2b-eb8e-4e08-91c3-57421eda73fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bf339-2936-4ed3-8059-f1acf7a2cd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = create_prompt(with_contra_random_samples[0], antiderivation_replacement_instruction)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d7ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from google_pygram import GooglePyGram as gpg\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from datasets import load_dataset\n",
    "from string import punctuation\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27c2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d84c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbab2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1c9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4bc2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(system_instruction, instruction, input):\n",
    "    message = create_prompt(input, instruction)\n",
    "    # message = instruction.format(sample = str(input))\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    # print(messages)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5bf19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ac32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_prompt(system_instruction, frequency_bias_instruction, with_contra_random_samples[0])[0]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f43131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_prompt(system_instruction, frequency_bias_instruction, with_contra_random_samples[0])[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c751e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def request(samples, prompt_type):\n",
    "    modified_samples = []\n",
    "    for sample in tqdm(samples):\n",
    "        # print(samples)\n",
    "        # create_prompt(sample, prompt_type)\n",
    "        messages = format_prompt(system_instruction, prompt_type, sample)\n",
    "        # print(messages)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=MODEL,\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            messages= messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "        ans_model = response['choices'][0]['message']['content']\n",
    "        modified_samples.append(ans_model)\n",
    "        # print(messages[1]['content'])\n",
    "        # print(sample)\n",
    "        # print(ans_model)\n",
    "        # print('===================')\n",
    "    return modified_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0ba5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsaharan_africa = ['Angola', 'Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cameroon', 'Cape Verde',\n",
    "          'Central African Republic', 'Chad', 'Comoros', 'Djibouti', 'Republic of the Congo', 'Democratic Republic of the Congo (Zaire)',\n",
    "          \"Côte d'Ivoire\", 'Equatorial Guinea', 'Eritrea', 'Ethiopia', 'Gabon', 'Gambia', 'Ghana', 'Guinea', \n",
    "          'Guinea-Bissau', 'Kenya', 'Lesotho', 'Liberia', 'Madagascar', 'Malawi', 'Mali', 'Mauritius', 'Mozambique', \n",
    "          'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'São Tomé and Príncipe', 'Senegal', 'Seychelles', 'Sierra Leone', \n",
    "          'Somalia', 'South Africa', 'South Sudan', 'Swaziland', 'Tanzania', 'Togo', 'Uganda']\n",
    "          \n",
    "\n",
    "#Middle East, North Africa, and Turkey\t\t   \n",
    "menat = ['Algeria', 'Bahrain', 'Iran', 'Iraq', 'Jordan', 'Egypt', 'Kuwait', 'Lebanon', 'Libya', 'Mauritania',\n",
    "          'Morocco', 'Oman', 'Palestine', 'Qatar', 'Saudi Arabia', 'Sudan', 'Syria', 'Turkey',\n",
    "          'Tunisia', 'United Arab Emirates', 'Yemen']\n",
    "\n",
    "\n",
    "southeast_asia = ['Brunei', 'Cambodia', 'Timor Leste', 'Indonesia', 'Laos', 'Malaysia', 'Myanmar',\n",
    "        'Philippines', 'Singapore', 'Thailand', 'Vietnam']\n",
    "\n",
    "east_asia = ['China', 'Japan', 'Mongolia', 'North Korea', 'South Korea', 'Taiwan']\n",
    "\n",
    "south_asia = ['Bangladesh', 'Bhutan', 'India', 'The Maldives', 'Nepal', 'Pakistan', 'Sri Lanka']\n",
    "\n",
    "central_asia = ['Afghanistan', 'Armenia', 'Azerbaijan', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', \n",
    "        'Tajikistan', 'Turkmenistan', 'Uzbekistan']\n",
    "\n",
    "\n",
    "#Oceania, Melanesia, and Polynesia\n",
    "oceania = ['Fiji', 'Federated States of Micronesia', 'Kiribati', 'Marshall Islands', 'Nauru', \n",
    "           'Palau', 'Papua New Guinea', 'Samoa', 'Solomon Islands', 'Tonga', 'Tuvalu', 'Vanuatu']\n",
    "\n",
    "australia_nz = ['Australia', 'New Zealand']\n",
    "\n",
    "\n",
    "#Carribean and Latin America\n",
    "latin_america = ['Mexico', 'Puerto Rico', 'Dominican Republic', 'Cuba', 'Haiti', 'Belize', 'Grenada', 'Saint Lucia',\n",
    "           'Costa Rica', 'El Salvador', 'Guatemala', 'Honduras', 'Nicaragua', 'Panama', 'Jamaica', 'Bahamas', 'Barbados',\n",
    "           'Dominica', 'Brazil', 'Argentina', 'Bolivia', 'Chile', 'Colombia', 'Ecuador', 'Guyana', 'Paraguay', 'Peru',\n",
    "           'Suriname', 'Trinidad and Tobago', 'Uruguay', 'Venezuela', 'Antigua and Barbuda', 'Saint Kitts and Nevis']\n",
    "\n",
    "north_america = ['Canada', 'United States of America']\n",
    "\n",
    "#Northern Europe (nordic)\n",
    "northern_europe = ['Denmark', 'Estonia', 'Finland', 'Iceland', 'Latvia', 'Lithuania', 'Norway', 'Sweden']\n",
    "\t\t   \n",
    "western_europe = ['Belgium', 'France', 'Republic of Ireland', 'Luxembourg', 'Monaco', 'Netherlands', 'United Kingdom']\n",
    "\n",
    "central_europe = ['Austria', 'Czech Republic', 'Germany', 'Hungary', 'Liechtenstein', 'Poland', 'Slovakia', 'Switzerland']\n",
    "\n",
    "southern_europe = ['Andorra', 'Italy', 'Malta', 'Portugal', 'San Marino', 'Spain', 'Vatican City']\n",
    "\n",
    "#Southeastern Europe (mostly Balkan)\n",
    "southeastern_europe = ['Albania', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus', 'Greece',\n",
    "          'Kosovo', 'North Macedonia', 'Moldova', 'Montenegro', 'Romania', 'Serbia', 'Slovenia']\n",
    "\t\t   \n",
    "eastern_europe = ['Russia', 'Belarus', 'Ukraine']\n",
    "regions = [subsaharan_africa, menat, southeast_asia, east_asia, central_asia, oceania, latin_america, southeastern_europe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c16ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_loc(system_instruction, instruction, input, region):\n",
    "    # print(input)\n",
    "    loc = random.sample(region,1)\n",
    "    message = create_prompt(input, instruction, loc = loc[0])\n",
    "    # message = instruction.format(sample = input, loc=loc)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28cceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sample, modification_instruction, loc = None, nonce = None):\n",
    "    index, instance = sample\n",
    "        \n",
    "    utterances = sorted(instance['turns'], key=lambda x: x['turn_id'])\n",
    "    last_utterance = utterances[-1]['text']\n",
    "    \n",
    "    if loc != None:\n",
    "        # print(loc)\n",
    "        modification_instruction = modification_instruction.format(loc = loc)\n",
    "        # print(modification_instruction)\n",
    "    if nonce != None:\n",
    "        modification_instruction = modification_instruction.format(nonce = nonce)\n",
    "\n",
    "    prompt = modification_instruction\n",
    "    prompt += \"\\n\\nDIALOGUE:\\n\" + \"\\n\".join([f\"Agent {u['agent_id']}: {u['text']}\" for u in utterances])\n",
    "    prompt += \"\\n\\nLAST TURN:\\n\" + last_utterance\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_prompt_loc(system_instruction, geographical_bias_instruction, no_contra_random_samples[0], subsaharan_africa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "315a6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def request_loc(samples, prompt_type):\n",
    "    modified_samples = []\n",
    "    for sample in tqdm(samples):\n",
    "        for region in regions:\n",
    "            # print(region)\n",
    "            messages = format_prompt_loc(system_instruction, prompt_type, sample, region)\n",
    "            # print(messages)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                response_format={ \"type\": \"json_object\" },\n",
    "                messages= messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            ans_model = response['choices'][0]['message']['content']\n",
    "            modified_samples.append(ans_model)\n",
    "            # print(sample)\n",
    "            # print(ans_model)\n",
    "        # print('===================')\n",
    "    return modified_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3f936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonce_words = [\"roagly\", \"vibble\", \"drok\", \"scrop\", \"plard\", \"hif\", \"tepable\", \"plawic\", \"bluth\", \"sprat\", \"flurf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9994e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_concepts(system_instruction, instruction, input):\n",
    "    \n",
    "    nonce = random.sample(nonce_words,1)\n",
    "    message = create_prompt(input, instruction, nonce = nonce)\n",
    "    # message = instruction.format(sample = input, nonce= nonce)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02d04760",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def request_concepts(samples, prompt_type):\n",
    "    modified_samples = []\n",
    "    for sample in tqdm(samples):\n",
    "        messages = format_prompt_concepts(system_instruction, prompt_type, sample)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=MODEL,\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            messages= messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "        ans_model = response['choices'][0]['message']['content']\n",
    "        modified_samples.append(ans_model)\n",
    "        # print(messages[1]['content'])\n",
    "        # print(sample)\n",
    "        # print(ans_model)\n",
    "        # print('===================')\n",
    "    return modified_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96349c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instance(sample):\n",
    "    index, instance = sample\n",
    "    contradiction_indices = instance['aggregated_contradiction_indices']\n",
    "    contradiction_indices = [x for x in contradiction_indices if x != len(instance['turns']) - 1]  # remove the last utterance, because it is always there\n",
    "    # print(\"contra ids\", contradiction_indices)\n",
    "    dialog = []\n",
    "    obj = {}\n",
    "    utterances = sorted(instance['turns'], key=lambda x: x['turn_id'])\n",
    "    for t in utterances:\n",
    "        # if t['turn_id'] in contradiction_indices:\n",
    "        #     print(Back.YELLOW + f\"{t['agent_id']}: {t['text']}\", end=\"\")\n",
    "        #     print(Style.RESET_ALL)\n",
    "        # elif t['auxiliary']['contradiction']:\n",
    "        #     print(Fore.RED + f\"{t['agent_id']}: {t['text']}\", end=\"\")\n",
    "        #     print(Style.RESET_ALL)\n",
    "        # else:\n",
    "        #     print(f\"{t['agent_id']}: {t['text']}\")\n",
    "        dialog.append(f\"{t['agent_id']}: {t['text']}\")\n",
    "    obj['id'] = index\n",
    "    obj['dialog'] = '\\n'.join(dialog)\n",
    "    obj['last_turn'] = utterances[-1]\n",
    "    return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b85ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_instance(no_contra_random_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c4263d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write original\n",
    "with open('decode_no/original.jsonl', 'w') as f:\n",
    "    for sample in no_contra_random_samples:\n",
    "        # object = show_instance(sample)\n",
    "        line = json.dumps(sample) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41540d6",
   "metadata": {},
   "source": [
    "# Bias tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0264e4f",
   "metadata": {},
   "source": [
    "### Frequency bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80be5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_bias_instruction = '''Replace one word of higher frequency in English vocabulary with a less frequent word. Add \"replaced_word\" and \"new_word\" fields to json output with the replaced and new words, accordingly.\n",
    "\n",
    "Example:\n",
    "\n",
    "Text: The cat licked its paw.\n",
    "Modified Text: The yak licked its paw.\n",
    "\n",
    "type: \"frequency_bias\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50f731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, frequency_bias_instruction)\n",
    "with open('decode_no/frequency_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb3fed",
   "metadata": {},
   "source": [
    "### Temporal bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad258935",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_bias_instruction = '''Please replace one word with its old-fashioned synonym. \n",
    "\n",
    "type: \"temporal_bias\"'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, temporal_bias_instruction)\n",
    "with open('decode_no/temporal_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a7b20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geographical_bias_instruction = '''Change the entity name in the sentence with name commonly used in {loc}. \n",
    "Change the other words in the sentence so that it is culturally fitted with context of {loc}.\n",
    "Write the modified sentences in English.\n",
    "\n",
    "type: \"geographical_bias\"'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3d2e9",
   "metadata": {},
   "source": [
    "### Geographical bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3364045",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request_loc(no_contra_random_samples, geographical_bias_instruction)\n",
    "with open('decode_no/geographical_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bd5d2",
   "metadata": {},
   "source": [
    "### Position bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3f372a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_bias_instruction = '''Move important sentiment words to another position in the same sentence.\n",
    "type: \"position_bias\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, position_bias_instruction)\n",
    "with open('decode_no/position_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71adee",
   "metadata": {},
   "source": [
    "### Length Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d688cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_bias_instruction = '''Modify the sentence length, but retain sentence meaning.\n",
    "\n",
    "1. \"shorter_sentence\": Remove 1 - 3 words from the sentence.\n",
    "2. \"longer_sentence\": Add 2 - 5 words to the sentence.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, length_bias_instruction)\n",
    "with open('decode_no/length_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d2c1b",
   "metadata": {},
   "source": [
    "## Orthography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72470a",
   "metadata": {},
   "source": [
    "### Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f67c2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "typo_instruction = '''Add typos to the text. Common types of typos are:\n",
    "\n",
    "1. \"addition\": Adding a letter: Forty (correct) vs. Fourty\n",
    "2. \"omission\": Omitting a letter: Embarrass (correct) vs. Embarass\n",
    "3. \"flipping\": flipping letters: Friend (correct) vs. Freind'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, typo_instruction)\n",
    "with open('decode_no/typo_bias.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9571f47",
   "metadata": {},
   "source": [
    "## Capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "404f0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitalization_instruction = '''Modify the text capitalization by:\n",
    "\n",
    "1. \"lower\": change a word with upper case to lower case.\n",
    "\n",
    "2. \"upper\": change a word starting with lower case to upper case.\n",
    "\n",
    "3. \"all_caps\": change a word to ALL CAPS.\n",
    "\n",
    "4. \"sponge\": change a word to SpOnGeBoBcASe.\n",
    "\n",
    "Reply with the modified text for each type of change.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88605cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, capitalization_instruction)\n",
    "with open('decode_no/capitalization.jsonl', 'w') as f:\n",
    "    for  i,item in enumerate(modified_samples):\n",
    "        object = json.loads(item)\n",
    "        print(i,object)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c4835",
   "metadata": {},
   "source": [
    "## Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "569549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_instruction = '''Make change to the punctuation of the text:\n",
    "\n",
    "1. \"addition\": add a random comma, semi-colon etc \n",
    "\n",
    "2. \"replacement\": change the full stop to the exclamation or question mark \n",
    "\n",
    "3. \"glueing\": remove white space between two words (glue them together). \n",
    "\n",
    "Reply with the modified text for each type of change.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, punctuation_instruction)\n",
    "with open('decode_no/punctuation.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48942d14",
   "metadata": {},
   "source": [
    "## Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ce5c4",
   "metadata": {},
   "source": [
    "## Derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab0f8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_replacement_instruction ='''Find a derived word (a word with a suffix or a prefix) in the text below and replace it with a non-derived word (word without any prefixes or suffixes).\n",
    "\n",
    "\n",
    "Example: a sometimes tedious film -> a sometimes dull film (tedious is derived from tedium using a -ios suffix)\n",
    "\n",
    "Example: a very good film -> Skip\n",
    "\n",
    "type: \"derivation\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, derivation_replacement_instruction)\n",
    "with open('decode_no/derivation.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba8e5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "antiderivation_replacement_instruction ='''Find any non-derived word (a word without suffixes or prefixes) in the text below and change it into a derived word (word with a prefix or a suffix). Do not add grammatical suffixes (-s, -ed, -er, -est).\n",
    "\n",
    "Example: a sometimes dull film ->  a sometimes tedious film (tedious is derived from tedium using a -ios suffix)\n",
    "\n",
    "Example: an very hard task -> an increasingly hard task (increasingly is derived from increasing using a -ly suffix)\n",
    "\n",
    "Example: amazing accomplishment -> Skip (both words are already derived)\n",
    "\n",
    "type: \"anti_derivation\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89884793",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, antiderivation_replacement_instruction)\n",
    "with open('decode_no/anti_derivation.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475b721",
   "metadata": {},
   "source": [
    "## Compound words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5296ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_word_instruction ='''Find any non-compond (single-root) word in the text below and change it into a compound word (word with several roots).\n",
    "\n",
    "type: \"compound_word\"\n",
    "\n",
    "Example: \n",
    "\"a sequence of ridiculous shooting scenes\" -> \"a sequence of ridiculous shoot-'em-up scenes\"\n",
    "Example: dull acting ->  lacklustre acting'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bdcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, compound_word_instruction)\n",
    "with open('decode_no/compound_word.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857d9ce",
   "metadata": {},
   "source": [
    "## Irregular verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "998f30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_verb_instruction ='''Find a regular verb in the past tense and replace it with an irregular verb.\n",
    "\n",
    "Example: he received a prize -> he got a prize\n",
    "\n",
    "Example: amazing stuff  ->  Skip'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f92f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, regular_verb_instruction)\n",
    "with open('decode_no/irregular_verb.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b4f5e",
   "metadata": {},
   "source": [
    "## Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb75419",
   "metadata": {},
   "source": [
    "### Active to passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13bfacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_voice_instruction = '''Rewrite the text in passive voice.\n",
    "\n",
    "type: \"passive_voice\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, passive_voice_instruction)\n",
    "with open('decode_no/active_to_passive.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4714df0",
   "metadata": {},
   "source": [
    "### Coordinating conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b23f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinating_conjunction_instruction = '''Change a noun or verb in this sentence into multiple nouns or verbs combined with coordinating conjunction.\n",
    "\n",
    "type: \"coordinating_conjunction\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68247945",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, coordinating_conjunction_instruction)\n",
    "with open('decode_no/coordinating_conjunction.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dc1ef",
   "metadata": {},
   "source": [
    "### Tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be22775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tense_instruction = '''Change the tense of verbs in the sentence. Keep the tenses consistent across the passage.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8896ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, tense_instruction)\n",
    "with open('decode_no/tense.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4abea1",
   "metadata": {},
   "source": [
    "### Grammatical role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c576a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammatical_role_instruction = '''Modify the position of grammatical role in the sentence.\n",
    "\n",
    "1. \"subject_object\": swap the subject with object\n",
    "Example: \n",
    "Miranda asked him a question. --> He asked Miranda a question.\n",
    "\n",
    "2. \"entities\": swap the position of other entities\n",
    "Example:\n",
    "Samantha, the older Rico's friend, will be appointed as Chair of Student Body replacing Marie. --> Marie, the older Samantha's friend, will be appointed as Chair of Student Body replacing Rico.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, grammatical_role_instruction)\n",
    "with open('decode_no/grammatical_role.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021aab15",
   "metadata": {},
   "source": [
    "### Clause structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be240ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_structure_instruction = '''Change the position of main and subordinate clause. If the input is simple sentence, skip.\n",
    "type: \"clause_structure\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, sentence_structure_instruction)\n",
    "with open('decode_no/clause_structure.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344258b",
   "metadata": {},
   "source": [
    "## Semantics and lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a0e89",
   "metadata": {},
   "source": [
    "## Concept replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc14a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_replacement_instruction ='''Replace a concept with one that is similar but fail the quality.\n",
    "\n",
    "Replacement types include:\n",
    "\n",
    "1. \"synonym\": synonyms\n",
    "Example: embodies the character with an effortlessly regal charisma . -> embodies the character with an effortlessly regal charm. (charm and charisma are synonyms)\n",
    "\n",
    "2. \"hierarchy\": hyper/hyponyms\n",
    "Example: The title not only describes its main characters, but the lazy people behind the camera as well. -> The title not only describes its main characters, but the lazy people behind the equipment as well. (equipment is a hypernym of camera)\n",
    "\n",
    "3. \"nonce\": the following nonce word: {nonce}\n",
    "Example: Has a lot of the virtues of eastwood at his best. - Has a lot of the virtues of bluth at his best. (bluth is a nonce word)\n",
    "\n",
    "4. \"idiom\": metaphors/idioms\n",
    "Example: This is a train wreck of an action film -> This is a disastrous action film (train wreck is a metaphor for disastrous)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request_concepts(no_contra_random_samples, concept_replacement_instruction)\n",
    "with open('decode_no/concept_replacement.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d03ed",
   "metadata": {},
   "source": [
    "## Adjectives/adverbs change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "724d6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_adverb_remove_instruction = '''Remove an adjective or adverb from the sentence.\n",
    "type: \"adjective_adverb_remove\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, adjective_adverb_remove_instruction)\n",
    "with open('decode_no/adjective_adverbs_remove.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec671921",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_adverb_add_instruction = '''Add an adjective or an adverb to the sentence.\n",
    "\n",
    "type: \"adjective_adverb_add\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, adjective_adverb_add_instruction)\n",
    "with open('decode_no/adjective_adverbs_add.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1abb26",
   "metadata": {},
   "source": [
    "## Pragmatics and discourse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702e31f",
   "metadata": {},
   "source": [
    "### Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d681ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_instruction = '''Negate the text by making minimal modifications to introduce different types of negation. The types of negation include:\n",
    "\n",
    "1. \"verbal\": verbal negation: when the negation is grammatically associated with the verb, the head of the clause.\n",
    "Examples:\n",
    "He trusts them. => He does not trust them.\n",
    "\n",
    "2. \"absolute\": Absolute negator: no (including compounds nobody, nothing, etc., and the independent form none), neither, nor, never.\n",
    "Example:\n",
    "He trusts them. => He trusts noone.\n",
    "\n",
    "3. \"approximate\": Approximate negators: few, little; barely, hardly, scarcely; rarely, seldom.\n",
    "Example:\n",
    "He trusts people. => He rarely trusts people.\n",
    "\n",
    "4. \"affixal\": Affixal negators: un-, in-, non-, -less, etc. Do not change the root of the word you add the affix to.\n",
    "Example:\n",
    "He is healthy => He is unhealthy.\n",
    "\n",
    "5. \"lexical\": Lexical negation: when the negation is added by substituting the main predicate of the sentence with its antonym or word carrying negative meaning.\n",
    "Examples:\n",
    "The house is big. => The house is small.\n",
    "\n",
    "6. \"unimportant\": Unimportant negation: when the negation does not affect the main clause of the text.\n",
    "Examples:\n",
    "A man is driving his car. => A shirtless man is driving his car.\n",
    "\n",
    "7. \"double\": Double negation: when there are two instances of negation that cancel each other and the meaning is affirmative.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb16ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, negation_instruction)\n",
    "with open('decode_no/negation.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e87927e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "antinegation_instruction = '''Check if the text contains negation, and if it does, remove it. Do not make any other modifications. If there is no negation, output Skip. \n",
    "\n",
    "type: \"remove_negation\"\n",
    "\n",
    "Examples:  \n",
    "\n",
    "Text: The house is not pretty. \n",
    "Modified text: The house is pretty.  \n",
    "\n",
    " \n",
    "Text: The story didn't leave anyone unaffected. \n",
    "Modified text: The story left everyone unaffected. \n",
    "\n",
    "\n",
    "Text: The house is pretty. \n",
    "Modified text: Skip.  ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, antinegation_instruction)\n",
    "with open('decode_no/remove_negation.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad40063",
   "metadata": {},
   "source": [
    "## Discourse markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84606d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_instruction = '''Make modification to the discourse makers in the text. The types of modification include:\n",
    "\n",
    "1. \"addition\": Add discourse markers to the sentence.\n",
    "Example:\n",
    "He was hungry, he went out to eat => He was hungry, so he went out to eat.\n",
    "\n",
    "2. \"replacement\": Change the discourse marker into a different one. If there is no discourse marker, output Skip.\n",
    "Example:\n",
    "He was hungry although he had dinner => He was hungry so he had dinner. (although => so)\n",
    "\n",
    "3. \"deletion\": Delete the discourse marker. If there is no discourse marker, output Skip.\n",
    "Example:\n",
    "He was hungry so he had dinner => He was hungry, he had dinner.\n",
    "\n",
    "For each type of modification, reply with the modified sentences.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66954952",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, discourse_instruction)\n",
    "with open('decode_no/discourse.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05efe2a5",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f44e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_instruction = '''Add a word or a phrase with a positive or negative sentiment to the sentence. \n",
    "\n",
    "Example: We beat the competition -> We are happy to beat the competition.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ede79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, sentiment_instruction)\n",
    "with open('decode_no/sentiment.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d2ea9",
   "metadata": {},
   "source": [
    "## Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558066c",
   "metadata": {},
   "source": [
    "### Casual vs formal style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4010a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_instruction = '''Rewrite the sentence in informal way.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, casual_instruction)\n",
    "with open('decode_no/casual.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1ed5d",
   "metadata": {},
   "source": [
    "### Simple vs Complex English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad1279",
   "metadata": {},
   "source": [
    "### Plain English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72c352f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_english_instruction = '''Please rewrite the sentence in order to make it easier to understand by non-native speakers of English. \n",
    "You can do so by replacing complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compres-sion), and/or splitting a long complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\n",
    "\n",
    "type: \"plain_english\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1312946",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, plain_english_instruction)\n",
    "with open('decode_no/plain_english.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d0509",
   "metadata": {},
   "source": [
    "### Complex English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32d7dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_english_instruction = '''Transform the original sentence into more complex English. \n",
    "Change some words with their more sophisticated technical synonym.\n",
    "Change the sentence structure into more complex one.\n",
    "Keep the modified sentence has nearly similar length with original one and do not alter its meaning.\n",
    "\n",
    "type: \"complex_english\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, complex_english_instruction)\n",
    "with open('decode_no/complex_english.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c0d43",
   "metadata": {},
   "source": [
    "### Dialectal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdfe3d",
   "metadata": {},
   "source": [
    "#### African American English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77494155",
   "metadata": {},
   "outputs": [],
   "source": [
    "aave_english_instruction = '''Rewrite the text in African American Vernacular English.\n",
    "\n",
    "type: \"aave_english\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a386fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, aave_english_instruction)\n",
    "with open('decode_no/aave_english.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f6a8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "singlish_instruction = '''Rewrite the text in Singapore Colloquial English (Singlish, Basilect).\n",
    "\n",
    "type: \"singlish\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd93dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, singlish_instruction)\n",
    "with open('decode_no/singlish.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0296592",
   "metadata": {},
   "source": [
    "#### Indian English "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee087e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "higlish_instruction = '''Rewrite the text using Indianisms and Indian English grammar.\n",
    "\n",
    "type: \"indian_english\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_samples = request(no_contra_random_samples, higlish_instruction)\n",
    "with open('decode_no/indian_english.jsonl', 'w') as f:\n",
    "    for item in modified_samples:\n",
    "        object = json.loads(item)\n",
    "        line = json.dumps(object) + \"\\n\"\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3200781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
